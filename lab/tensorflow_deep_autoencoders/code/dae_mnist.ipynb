{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dae_mnist.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"I68iLf3I47wH","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from tensorflow.keras.datasets import mnist\n","from sklearn.preprocessing import OneHotEncoder\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","target_enc = OneHotEncoder().fit(y_train.reshape(-1,1))\n","y_train = target_enc.transform(y_train.reshape(-1,1)).todense()\n","y_test = target_enc.transform(y_test.reshape(-1,1)).todense()\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","\n","h, w = 28, 28\n","num_classes = 10\n","noise_mean, noise_stddev = 0.0, 0.3\n","\n","def collapse(batch):\n","  return np.reshape(batch, (batch.shape[0], -1))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BvsmGQ095HFg","colab_type":"code","colab":{}},"cell_type":"code","source":["num_sample_per_class = 5\n","num_row, num_col = 10, num_sample_per_class*2\n","f,subplots = plt.subplots(num_row, num_col, sharex='col', sharey='row')\n","\n","Xnoisy = x_train + np.random.normal(noise_mean,noise_stddev,(x_train.shape[0],h,w))\n","\n","for digit in range(num_classes):\n","      digit_idxs = np.argmax(y_train,axis=1) == digit\n","      digit_idxs = np.arange(0,x_train.shape[0]).reshape((-1,1))[digit_idxs]\n","      digit_idxs = np.random.choice(digit_idxs, num_sample_per_class)\n","      \n","      for num_sample, sample in enumerate(digit_idxs):\n","          subplots[digit,num_sample].imshow(x_train[sample], cmap='gray', aspect='auto')\n","          subplots[digit,num_sample].grid(b=False)\n","          subplots[digit,num_sample].axis('off')\n","          \n","      for num_sample, sample in enumerate(digit_idxs):\n","          num_sample = num_sample + len(digit_idxs)\n","          subplots[digit,num_sample].imshow(Xnoisy[sample], cmap='gray', aspect='auto')\n","          subplots[digit,num_sample].grid(b=False)\n","          subplots[digit,num_sample].axis('off')\n","\n","f.suptitle(\"Class-wise Clean vs Noisy MNIST images\")\n","f.set_size_inches(8.5, 7.5, forward=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Qtz-hCnO5p5t","colab_type":"code","colab":{}},"cell_type":"code","source":["class DeepDenoisingAutoencoder:\n","  \n","  def __init__(self, x, is_training, layers=[512, 384, 256], \n","               noise_mean=0.0, noise_stddev=0.3, act=tf.nn.leaky_relu):\n","    \n","    self.x, self.is_training = x, is_training\n","    self.noise_mean, self.noise_stddev  = noise_mean, noise_stddev\n","    self.act = act\n","    self.layers = layers\n","    \n","    self.noisy_x, self.bottleneck, self.output = None, None, None\n","    self.loss, self.train_step = None, None\n","  \n","  def noisy(self):\n","    \"\"\" \n","    ----------------------------------- TODO -----------------------------------\n","    Given the input images self.x, write the code for injecting noise on them. \n","    The noise should be sampled from a multivariate gaussian, with mean equals \n","    to self.noise_mean and standard dev. equals to self.noise_stddev.\n","    \n","    See tf.random_normal for additional details.\n","    \"\"\"\n","    if self.noisy_x is None:\n","      self.noisy_x = None\n","    return self.noisy_x\n","  \n","  def encoder(self, inp):\n","    \"\"\"\n","    ----------------------------------- TODO -----------------------------------\n","    Given self.layers, a list indicating for each layer the desider number of \n","    ouput features, write here the encoding function.\n","    \"\"\"\n","    h = None\n","    return h\n","        \n","  def decoder(self, inp):\n","    \"\"\"\n","    ----------------------------------- TODO -----------------------------------\n","    Write here the decoding function. Please note that it should ensemble the\n","    encoder architecture, thus mirroring the projection pattern described in \n","    self.layers. \n","    \"\"\"\n","    h = None\n","    return h\n","  \n","  def inference(self):\n","    \"\"\"\n","    ----------------------------------- TODO -----------------------------------\n","    Write here the inference method, which will set up the entire denoising \n","    autoencoder. \n","    \n","    1) Call self.noisy() to create the input noisy tensor.\n","    \n","    2) Based on the value of self.is_training, feed the model with the corrupted\n","    images (when self.is_training is True) or, instead, with the clean ones. \n","        - See tf.cond() for additional details\n","        \n","    3) Call the encoder function and store its ouptut in self.bottleneck,\n","    the latter representing the activations of the bottleneck layer.\n","    \n","    4) Call the decoder function, which will provide the input reconstruction \n","    from the bottleneck layer.\n","    \"\"\"\n","    input_to_net = None\n","    self.bottleneck = None\n","    self.output = None\n","    return self.output\n","  \n","  def get_loss(self):\n","    \"\"\"\n","    ----------------------------------- TODO -----------------------------------\n","    Write here the Mean Squared Error (MSE) loss function. \n","    \"\"\"\n","    if self.loss is None:\n","      self.loss = None\n","    return self.loss\n","  \n","  def get_bottleneck(self):\n","    return self.bottleneck\n","  \n","  def get_train_step(self):\n","    if self.train_step is None:\n","      update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n","      with tf.control_dependencies(update_ops):\n","        self.train_step = tf.train.AdamOptimizer(learning_rate=0.001).minimize(self.get_loss())\n","    return self.train_step\n","  \n","  def compute_hiddens(self, sess, X_data, batch_size=512):\n","    len_X = X_data.shape[0]\n","    num_forwards, rest = len_X // batch_size, len_X % batch_size\n","    hiddens = []\n","    \n","    def run(x_batch):\n","      return sess.run(self.get_bottleneck(), feed_dict={self.x: collapse(x_batch), self.is_training:False})\n","    \n","    for j in range(num_forwards):\n","      hiddens.append(run(X_data[j*batch_size:(j+1)*batch_size]))\n","    \n","    if rest > 0:\n","      hiddens.append(run(X_data[batch_size*num_forwards:len_X]))\n","      \n","    return np.concatenate(hiddens, axis=0)\n","\n","# Define model output\n","x = tf.placeholder(dtype=tf.float32, shape=[None, 784]) \n","is_training = tf.placeholder(dtype=tf.bool)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jrXGchyM5Jsl","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn import tree\n","from sklearn.metrics import accuracy_score\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","with tf.Session() as sess:\n","     \n","  dae = DeepDenoisingAutoencoder(x, is_training, noise_mean=noise_mean, \n","                                 noise_stddev=noise_stddev)\n","\n","  output = dae.inference()\n","  loss = dae.get_loss()\n","  train_step = dae.get_train_step()\n","\n","  init_op = tf.global_variables_initializer()\n","\n","  # Initialize all variables\n","  sess.run(init_op)\n","\n","  # Training parameters\n","  training_epochs = 5\n","  batch_size      = 128\n","\n","  # Number of batches to process to see whole dataset\n","  batches_each_epoch = x_train.shape[0] // batch_size\n","\n","  for epoch in range(training_epochs):\n","\n","    val_loss = sess.run(loss, feed_dict={is_training:True, x: collapse(x_test)})\n","    print('Epoch: {:06d} - Test Loss : {:.03f}'.format(epoch, val_loss))\n","\n","    x_train_rec, x_train_noisy = [], []\n","    for i in range(batches_each_epoch):\n","\n","      x_batch = x_train[i*batch_size:(i+1)*batch_size]\n","      sess.run(train_step, feed_dict={is_training:True, x: collapse(x_batch)})\n","      \n","      rec, noisy_x = sess.run([output, dae.noisy(), ], feed_dict={x: collapse(x_batch), is_training:True})\n","      x_train_rec.append(rec)\n","      x_train_noisy.append(noisy_x)\n","\n","    x_train_rec = np.concatenate(x_train_rec, axis=0)\n","    x_train_noisy = np.concatenate(x_train_noisy, axis=0)\n","\n","    x_train_features = dae.compute_hiddens(sess, x_train)\n","    x_test_features = dae.compute_hiddens(sess, x_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hb8ALoUp57KN","colab_type":"code","colab":{}},"cell_type":"code","source":["num_sample_per_class = 5\n","\n","def plot_img(subplot, img):\n","  subplot.imshow(img, cmap='gray', aspect='auto')\n","  subplot.grid(b=False)\n","  subplot.set_xticks([])\n","  subplot.set_yticks([])\n","  \n","f,subplots = plt.subplots(num_classes, num_sample_per_class*3, sharex='col', sharey='row')\n","\n","for digit in range(num_classes):\n","      \n","      digit_idxs = np.argmax(y_train[0:x_train_rec.shape[0]],axis=1) == digit\n","      digit_idxs = np.arange(0,x_train_rec.shape[0]).reshape((-1,1))[digit_idxs]\n","      digit_idxs = np.random.choice(digit_idxs, num_sample_per_class)\n","      \n","      for num_sample, sample in enumerate(digit_idxs):\n","          plot_img(subplots[digit, num_sample], x_train[sample])\n","          plot_img(subplots[digit, num_sample_per_class + num_sample], x_train_noisy[sample].reshape((h,w)))\n","          plot_img(subplots[digit, 2*num_sample_per_class + num_sample], x_train_rec[sample].reshape((h,w)))\n","\n","subplots[0, num_sample_per_class//2].set_title(\"Input\")\n","subplots[0, num_sample_per_class + num_sample_per_class//2].set_title(\"Noisy input\")\n","subplots[0, 2*num_sample_per_class + num_sample_per_class//2].set_title(\"Reconstruction\")\n","  \n","f.set_size_inches(12.5, 7.5, forward=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PaxcWpwI5Mum","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","def evaluation(x_train, y_train, x_test, y_test, num_sample_per_class, n_neighbors=1):\n","  num_classes = y_train.shape[1]\n","  balanced_x_train, balanced_y_train = [], []\n","  \n","  for digit in range(num_classes):\n","    digit_idxs = np.argmax(y_train,axis=1) == digit\n","    digit_idxs = np.arange(0,y_train.shape[0]).reshape((-1,1))[digit_idxs]\n","    digit_idxs = np.random.choice(digit_idxs, num_sample_per_class)\n","    balanced_x_train.append(x_train[digit_idxs])\n","    balanced_y_train.append(y_train[digit_idxs])\n","  \n","  balanced_x_train = np.concatenate(balanced_x_train, axis=0)\n","  balanced_y_train = np.concatenate(balanced_y_train, axis=0)\n","    \n","  clf = KNeighborsClassifier(n_neighbors=1)\n","  clf.fit(balanced_x_train, balanced_y_train)  \n","  \n","  return accuracy_score(y_test, clf.predict(x_test))\n","\n","num_sample_per_class = 100\n","print(\"Evaluation with training set size: {}\".format(num_sample_per_class*num_classes))\n","acc_raw = evaluation(collapse(x_train), y_train, collapse(x_test), y_test, num_sample_per_class)\n","acc_dae = evaluation(x_train_features, y_train, x_test_features, y_test, num_sample_per_class)\n","print(\"Test set accuracy from grayscale features {0:.3f}\".format(acc_raw))\n","print(\"Test set accuracy from DAE features {0:.3f}\".format(acc_dae))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4GfuJFfBFjqt","colab_type":"code","colab":{}},"cell_type":"code","source":["accuracies_raw_features, accuracies_dae_features = [], []\n","\n","num_sample_list = list(range(20,101,20))\n","for num_sample_per_class in num_sample_list:\n","  print(\"*\"*50)\n","  print(\"Evaluation with training set size: {}\".format(num_sample_per_class*num_classes))\n","  acc_raw = evaluation(collapse(x_train), y_train, collapse(x_test), y_test, num_sample_per_class)\n","  acc_dae = evaluation(x_train_features, y_train, x_test_features, y_test, num_sample_per_class)\n","  print(\"Test set accuracy from grayscale features {0:.3f}\".format(acc_raw))\n","  print(\"Test set accuracy from DAE features {0:.3f}\".format(acc_dae))\n","  accuracies_raw_features.append(acc_raw)\n","  accuracies_dae_features.append(acc_dae)\n","  \n","plt.plot(num_classes*np.array(num_sample_list), accuracies_raw_features, label=\"Grayscale features\")\n","plt.plot(num_classes*np.array(num_sample_list), accuracies_dae_features, label=\"Denoising AE features\")\n","plt.xlabel(\"Num. of labeled sample in the training set.\")\n","plt.ylabel(\"Test set classification accuracy\")\n","plt.legend()\n","pass"],"execution_count":0,"outputs":[]}]}